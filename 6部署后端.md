部署规划
10.0.0.99 master
10.0.0.44 node1
10.0.0.74 node2
10.0.0.121 node3 
10.0.0.72 node4 #data set
10.0.0.124 node5 #NFS
10.0.0.118 node6 #front&back
#k8s集群为master+node1-3
#k8s版本为1.16.2
#docker版本为19.03.12
#calico版本为v3.9.0
#k8s pod网段为192.168.0.0/16
#k8s service网段为172.16.0.0/16

#本段操作如非特别说明，请在node6操作
#首先使用coredns配置泛域名解析（master节点操作）
kubectl edit cm -n kube-system coredns
#在ready下一行添加如下字段（注意缩进）
        template IN A notebook.duhao.com serving.duhao.com api.duhao.com {
            answer "{{ .Name }} 60 IN A 10.0.0.99"
            fallthrough
        }


#过两分钟后ping下列地址 观察是否能解析至10.0.0.99
ping 1.notebook.duhao.com -c1
ping ddd.serving.duhao.com -c1
ping asd123.api.duhao.com -c1

#部署mysql
apt install mysql-server -y 
vim /etc/mysql/mysql.conf.d/mysqld.cnf
将bind-address            = 127.0.0.1-address            = 0.0.0.0
systemctl enable --now  mysql
systemctl restart mysql
#配置mysql权限
mysql -uroot -proot   设置了数据库密码为root
GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' IDENTIFIED BY 'root' WITH GRANT OPTION;

#部署后端       ###这里10.0.0.118地址是部署数据库的地址（数据库部署在那个地址就填那个IP）
cd /nfs/Dubhe/dubhe-server/sql/
apt install mysql-client openjdk-8-jdk maven jq -y 
mysql -uroot -proot -h 10.0.0.118 < 00-Dubhe-DB.sql                 
mysql -uroot -proot -h 10.0.0.118 < 01-Dubhe-DDL.sql
mysql -uroot -proot -h 10.0.0.118 < 02-Dubhe-DML.sql

mysql -uroot -proot -h 10.0.0.118 < 09-Dubhe-Patch.sql
mysql -uroot -proot -h 10.0.0.118 < 11-Dubhe-Patch-3.0.sql
# 数据集路径
mkdir /nfs/dubhe-prod/dataset/  
# 算法文件路径               
mkdir /nfs/dubhe-prod/algorithm-manage/        
# 预置算法文件路径      
mkdir /nfs/dubhe-prod/algorithm-manage/common/ 
# 训练文件路径               
mkdir /nfs/dubhe-prod/train-manage/
# 模型文件路径
mkdir /nfs/dubhe-prod/model/   
# 预置模型文件路径
mkdir /nfs/dubhe-prod/model/common/                 
# 模型优化文件路径  
mkdir /nfs/dubhe-prod/model-opt/
# 上传文件临时路径  
mkdir /nfs/dubhe-prod/upload-temp/
# 镜像文件路径
mkdir /nfs/dubhe-prod/upload-image/
# 云端部署文件路径
mkdir /nfs/dubhe-prod/serving/
#安装docker kubectl 
curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -
add-apt-repository "deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable"
curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - 
cat <<EOF >/etc/apt/sources.list.d/kubernetes.list
deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main
EOF
apt update
apt -y install docker-ce=5:19.03.12~3-0~ubuntu-bionic kubectl=1.16.2-00
mkdir /root/.kube/ 
scp master:/root/.kube/config /root/.kube/config 




scp master:/root/.kube/config /nfs/Dubhe/dubhe_data_process/dubheDeployScriptfile/cloud/dubhe/kubeconfig.yaml 


#配置docker
mkdir /etc/docker
vim /etc/docker/daemon.json
#添加
{ "insecure-registries": ["https://harbor.wsco.com"] }

systemctl daemon-reload &&systemctl restart docker
#修改脚本
vim /nfs/Dubhe/dubhe_data_process/dubheDeployScriptfile/cloud/change_nacos.sh 
将cd Dubhe/dubhe-server/yaml修改为/nfs/Dubhe/dubhe-server/yaml
将rsync -av --exclude README.md /Dubhe/dubhe-server/yaml/ dubhe 修改为rsync -av --exclude README.md /nfs/Dubhe/dubhe-server/yaml/ dubhe
#部署nacos
mkdir /Dubhe
cd /nfs/Dubhe/dubhe_data_process/dubheDeployScriptfile/cloud
bash nacos_deploy.sh 
##如果服务没起来进入此目录执行命令启动
cd /Dubhe/nacos/bin
./startup.sh -m standalone
#./Dubhe/nacos/bin/startup.sh -m standalone
#打开网页 http://10.0.0.118:8848/nacos
#用户名密码均为nacos
cd dubhe
#修改文件夹里所有yaml文件的配置后
#将文件打包上传至nacos配置中心
cd /nfs/Dubhe/dubhe_data_process/dubheDeployScriptfile/cloud
rm dubhe.zip
zip -r dubhe.zip dubhe
apt install lrzsz
sz dubhe.zip    ##这条命令会把压缩文件上传到桌面，直接到浏览器登录nacos，上传配置就可以了


#修改nacos配置
cd /nfs/Dubhe/dubhe-server
find . -name bootstrap.yml |xargs -n 1 sed -i 's\dubhe-server-cloud-dev\dubhe-server-cloud-prod\g' 
#执行此命令查看nacos注册地址是否存在非127.0.0.1 如有请改正
find . -name bootstrap.yml |xargs -p -n 1 cat |grep server-addr
！！！执行后一直按y
#构建
# 回到项目根目录,执行构建
cd /nfs/Dubhe/dubhe-server
# 构建，生成的jar包位于 ./dubhe-admin/target/dubhe-admin-1.0-exec.jar ./dubhe-task/target/dubhe-task-1.0.jar
mvn clean compile package
# 启动应用服务端

mkdir -p /nfs/Dubhe/dubhe-server/common-k8s/src/main/resources

cp /root/.kube/config /nfs/Dubhe/dubhe-server/common-k8s/src/main/resources/kubeconfig

cd /nfs/Dubhe/dubhe-server/

nohup java -jar auth/target/auth-0.0.1-SNAPSHOT-exec.jar                     -Xms2048M   --spring.profiles.active=prod  > /dev/null 2>&1 &
nohup java -jar admin/target/admin-0.0.1-SNAPSHOT-exec.jar                    -Xms2048M     --spring.profiles.active=prod  > /dev/null 2>&1 &
nohup java -jar dubhe-algorithm/target/dubhe-algorithm-0.0.1-SNAPSHOT-exec.jar -Xms2048M    --spring.profiles.active=prod  > /dev/null 2>&1 &
nohup java -jar dubhe-data/target/dubhe-data-0.0.1-SNAPSHOT-exec.jar          -Xms2048M     --spring.profiles.active=prod  > /dev/null 2>&1 &
nohup java -jar dubhe-data-dcm/target/dubhe-data-dcm-0.0.1-SNAPSHOT-exec.jar   -Xms2048M    --spring.profiles.active=prod  > /dev/null 2>&1 &
nohup java -jar dubhe-data-task/target/dubhe-data-task-0.0.1-SNAPSHOT-exec.jar -Xms2048M    --spring.profiles.active=prod  > /dev/null 2>&1 &
nohup java -jar dubhe-image/target/dubhe-image-0.0.1-SNAPSHOT-exec.jar         -Xms2048M    --spring.profiles.active=prod  > /dev/null 2>&1 &
nohup java -jar dubhe-k8s/target/dubhe-k8s-0.0.1-SNAPSHOT-exec.jar             -Xms2048M    --spring.profiles.active=prod  > /dev/null 2>&1 &
nohup java -jar dubhe-measure/target/dubhe-measure-0.0.1-SNAPSHOT-exec.jar     -Xms2048M    --spring.profiles.active=prod  > /dev/null 2>&1 &
nohup java -jar dubhe-model/target/dubhe-model-0.0.1-SNAPSHOT-exec.jar        -Xms2048M     --spring.profiles.active=prod  > /dev/null 2>&1 &
nohup java -jar dubhe-notebook/target/dubhe-notebook-0.0.1-SNAPSHOT-exec.jar  -Xms2048M     --spring.profiles.active=prod  > /dev/null 2>&1 &
nohup java -jar dubhe-optimize/target/dubhe-optimize-0.0.1-SNAPSHOT-exec.jar  -Xms2048M     --spring.profiles.active=prod  > /dev/null 2>&1 &
nohup java -jar dubhe-serving/target/dubhe-serving-0.0.1-SNAPSHOT-exec.jar   -Xms2048M       --spring.profiles.active=prod  > /dev/null 2>&1 &
nohup java -jar dubhe-serving-gateway/target/dubhe-serving-gateway-0.0.1-SNAPSHOT-exec.jar    -Xms2048M     --spring.profiles.active=prod  > /dev/null 2>&1 &
nohup java -jar dubhe-train/target/dubhe-train-0.0.1-SNAPSHOT-exec.jar        -Xms2048M     --spring.profiles.active=prod  > /dev/null 2>&1 &
nohup java -jar gateway/target/gateway-0.0.1-SNAPSHOT-exec.jar               -Xms2048M      --spring.profiles.active=prod  > /dev/null 2>&1 &
nohup java -jar dubhe-tadl/target/dubhe-tadl-0.0.1-SNAPSHOT-exec.jar        -Xms2048M     --spring.profiles.active=prod  > /dev/null 2>&1 &


##如果重启服务需要把除了nacos之外的所有服务都杀掉命令如下：

jps |grep -v nacos |awk '{print $1}' |xargs -n 1 kill -9   



#部署可视化后端服务
cd /nfs/Dubhe/dubhe-visual-server
#执行init.sh脚本，下载并安装 conda 环境，并创建代码运行环境 dubhe-virtual（python3.7.7）
#用source执行脚本，不要使用bash执行，脚本执行过程中需要Enter或者输入yes，请按提示操作
source init.sh
# 启动可视化服务
cd /nfs/Dubhe/dubhe-visual-server
source start_server.sh
#检查
ps -ef |grep python


## 补充拉取notebook官方预置镜像
拉取命令： docker pull registry.cn-hangzhou.aliyuncs.com/enlin/notebook:v1
打上标签： docker tag  registry.cn-hangzhou.aliyuncs.com/enlin/notebook:v1  harbor.wsco.com/notebook/notebook:V1 
上传镜像到harbor仓库： docker push harbor.wsco.com/notebook/notebook:V1  

使用此命令改数据库是的镜像生效： 
INSERT INTO `dubhe-cloud-prod`.`pt_image` (`id`, `project_name`, `image_resource`, `image_status`, `image_name`, `image_url`, `image_tag`, `remark`, `create_user_id`, `create_time`, `update_user_id`, `update_time`, `deleted`, `origin_user_id`, `ssh_pwd`, `ssh_user`) VALUES (28, 'train', 0, 1, 'notebook', 'notebook/notebook:v1', 'v1', NULL, 1, '2022-06-15 11:25:09', 1, '2022-06-15 11:25:23', 0, 0, NULL, NULL);



 cd /nfs/Dubhe/dubhe-server/

 
java -jar auth/target/auth-0.0.1-SNAPSHOT-exec.jar                     -Xms2048M       ##查看报错的时候如果有数据库密码不需要网页登录nacos找到上传的配置文件common-shardingjdbc.yaml  ，common-biz.yaml  这两个配置文件在里面把数据库密码改为root 密码是上面命令设置的


java -jar admin/target/admin-0.0.1-SNAPSHOT-exec.jar                    -Xms2048M  

java -jar dubhe-algorithm/target/dubhe-algorithm-0.0.1-SNAPSHOT-exec.jar -Xms2048M        ### 报错1111111

java -jar dubhe-data/target/dubhe-data-0.0.1-SNAPSHOT-exec.jar          -Xms2048M  

java -jar dubhe-data-dcm/target/dubhe-data-dcm-0.0.1-SNAPSHOT-exec.jar   -Xms2048M 

java -jar dubhe-data-task/target/dubhe-data-task-0.0.1-SNAPSHOT-exec.jar -Xms2048M  

java -jar dubhe-image/target/dubhe-image-0.0.1-SNAPSHOT-exec.jar         -Xms2048M      ####报错11111111

java -jar dubhe-k8s/target/dubhe-k8s-0.0.1-SNAPSHOT-exec.jar             -Xms2048M        ####报错111111

java -jar dubhe-measure/target/dubhe-measure-0.0.1-SNAPSHOT-exec.jar     -Xms2048M       ###报错1111111111

java -jar dubhe-model/target/dubhe-model-0.0.1-SNAPSHOT-exec.jar        -Xms2048M          ###报错111111111

java -jar dubhe-notebook/target/dubhe-notebook-0.0.1-SNAPSHOT-exec.jar  -Xms2048M       ####报错  1111111111111111111

java -jar dubhe-optimize/target/dubhe-optimize-0.0.1-SNAPSHOT-exec.jar  -Xms2048M        ###报错

java -jar dubhe-serving/target/dubhe-serving-0.0.1-SNAPSHOT-exec.jar   -Xms2048M        ###报错

java -jar dubhe-serving-gateway/target/dubhe-serving-gateway-0.0.1-SNAPSHOT-exec.jar    -Xms2048M     ###报错

java -jar dubhe-train/target/dubhe-train-0.0.1-SNAPSHOT-exec.jar        -Xms2048M       ###报错

java -jar gateway/target/gateway-0.0.1-SNAPSHOT-exec.jar               -Xms2048M     

java -jar dubhe-tadl/target/dubhe-tadl-0.0.1-SNAPSHOT-exec.jar        -Xms2048M      ###报错







#####有报错需要查看nacos有没有起来   redis有没有起来   jar包有没有起来

nacos有没有起来通过网页登录看是否能够登录上去

redis是否启动看用命令 systemctl status redis.service 

jar包是否起来先cd 进/etc/nginx/sites-available   输入命令看jps看到页面有几个服务在，正常全部部署上是19个所有都算上


如果重新启动jar包需要用以下命令杀掉除了nacos之外的jar进程
然后cd 进入/nfs/Dubhe/dubhe-server/ 目录下，使用上面的命令重启jar包

kubectl describe pods -n kube-system <pod_name>查看pod具体运行状态