部署规划
10.0.0.99 master
10.0.0.44 node1
10.0.0.74 node2
10.0.0.121 node3 
10.0.0.72 node4 #data set
10.0.0.124 node5 #NFS
10.0.0.118 node6 #front&back
#k8s集群为master+node1-3
#k8s版本为1.16.2
#docker版本为19.03.12
#calico版本为v3.9.0
#k8s pod网段为192.168.0.0/16
#k8s service网段为172.16.0.0/16

##########################################################系统不要upgrade  不要upgrade   不要upgrade################
#本段操作如非特别说明，请在k8s集群所有节点操作
#配置主机名称
hostnamectl set-hostname master01
#写入hosts
cat >> /etc/hosts <<EOF
10.0.0.99 master
#10.0.0.44 node1
#10.0.0.74 node2
10.0.0.121 node1 
10.0.0.72 node4 #data set
10.0.0.124 node5 #NFS
10.0.0.118 node6 #front&back
EOF

#关闭防火墙
systemctl disable ufw --now;

#关闭swap
swapoff -a;yes | cp /etc/fstab /etc/fstab_bak;cat /etc/fstab_bak |grep -v swap > /etc/fstab

#配置ulimit
ulimit -SHn 65535
cat >> /etc/security/limits.conf <<EOF
* soft nofile 655360
* hard nofile 131072
* soft nproc 655350
* hard nproc 655350
* soft memlock unlimited
* hard memlock unlimited
EOF

#加载内核模块
modprobe br_netfilter

#查看
lsmod | grep br_netfilter

#配置内核参数
cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1 
net.bridge.bridge-nf-call-iptables = 1 
net.ipv4.ip_forward = 1 
vm.swappiness = 0
EOF
sysctl -p /etc/sysctl.d/k8s.conf

#安装依赖
apt update&& apt -y install apt-transport-https ca-certificates curl software-properties-common ntpdate ipset ipvsadm

#配置时区
ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime

#配置时间同步
echo '0 */1 * * * root ntpdate time1.aliyun.com' >> /etc/crontab

#配置ipvs
#创建sysconfig/modules文件夹
mkdir -p /etc/sysconfig/modules/

cat >>/etc/sysconfig/modules/ipvs.modules <<EOF
#!/bin/bash
modprobe -- ip_vs
modprobe -- ip_vs_rr
modprobe -- ip_vs_wrr
modprobe -- ip_vs_sh
modprobe -- nf_conntrack_ipv4
EOF

#检查ipvs
chmod 755 /etc/sysconfig/modules/ipvs.modules && bash /etc/sysconfig/modules/ipvs.modules && lsmod | grep -e ip_vs -e nf_conntrack_ipv4

#安装GPG证书
curl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -

#写入软件源信息
add-apt-repository "deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable"

distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \
      && curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \
      && curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \
            sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
            tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

curl https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg | apt-key add - 

cat <<EOF >/etc/apt/sources.list.d/kubernetes.list
deb https://mirrors.aliyun.com/kubernetes/apt/ kubernetes-xenial main
EOF
apt update

#安装 Docker-CE及nvidia-container-runtime
apt -y install docker-ce=5:19.03.12~3-0~ubuntu-bionic

apt -y install nvidia-docker2

#修改docker配置文件
cat <<EOF > /etc/docker/daemon.json
{
   "default-runtime": "nvidia",
   "runtimes": {
       "nvidia": {
           "path": "/usr/bin/nvidia-container-runtime",
           "runtimeArgs": []
       }
   },
  "exec-opts": ["native.cgroupdriver=systemd"],
  "registry-mirrors": ["https://iydpb1np.mirror.aliyuncs.com"],
  "insecure-registries": ["https://harbor.wsco.com"] 
}
EOF

#重启docker
systemctl daemon-reload && systemctl restart docker && systemctl enable docker

#安装k8s组件
apt install -y kubelet=1.16.2-00 kubeadm=1.16.2-00 kubectl=1.16.2-00

#配置k8s集群参数（此步骤仅在master执行）
cat <<EOF > kubeadm-config.yaml
apiVersion: kubeadm.k8s.io/v1beta2
bootstrapTokens:
- groups:
  - system:bootstrappers:kubeadm:default-node-token
  token: abcdef.0123456789abcdef
  ttl: 24h0m0s
  usages:
  - signing
  - authentication
kind: InitConfiguration
localAPIEndpoint:
  advertiseAddress: 10.0.0.99            ###这里是master节点地址
  bindPort: 6443
nodeRegistration:
  criSocket: /var/run/dockershim.sock
  imagePullPolicy: IfNotPresent
  name: master
  taints:
  - effect: NoSchedule
    key: node-role.kubernetes.io/master
---
apiServer:
  timeoutForControlPlane: 4m0s
apiVersion: kubeadm.k8s.io/v1beta2
certificatesDir: /etc/kubernetes/pki
clusterName: kubernetes
controlPlaneEndpoint: 10.0.0.99:6443
controllerManager: {}
dns:
  type: CoreDNS
etcd:
  local:
    dataDir: /var/lib/etcd
imageRepository: registry.cn-hangzhou.aliyuncs.com/google_containers
kind: ClusterConfiguration
kubernetesVersion: v1.16.0
networking:
  dnsDomain: cluster.local
  podSubnet: 192.168.0.0/16
  serviceSubnet: 172.16.0.0/16
scheduler: {}
EOF

#初始化k8s集群（此步骤仅在master执行）
kubeadm init --config=kubeadm-config.yaml --upload-certs


##记录获取加入k8s集群的秘钥和令牌
kubeadm join 10.0.0.99:6443 --token abcdef.0123456789abcdef \
    --discovery-token-ca-cert-hash sha256:d70bea96a3ea05cb217fbb775069611c729b11f9132092744315cbf3b06ee292 


#配置kubectl（此步骤仅在master执行）
rm -rf /root/.kube/
mkdir /root/.kube/
cp -i /etc/kubernetes/admin.conf /root/.kube/config
kubectl completion bash > ~/.kube/completion.bash.inc &&echo source ~/.kube/completion.bash.inc >> /root/.bashrc &&source ~/.kube/completion.bash.inc

#缩减coredns副本数（此步骤仅在master执行）
kubectl scale --replicas=1 deployment -n kube-system coredns

#安装calico（此步骤仅在master执行）
wget https://kuboard.cn/install-script/calico/calico-3.10.2.yaml
kubectl apply -f calico-3.10.2.yaml 

#安装nvidia-device-plugin（此步骤仅在master执行）
cat <<EOF > nvidia-device-plugin.yml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: nvidia-device-plugin-daemonset
  namespace: kube-system
spec:
  selector:
    matchLabels:
      name: nvidia-device-plugin-ds
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        name: nvidia-device-plugin-ds
    spec:
      tolerations:
      - key: nvidia.com/gpu
        operator: Exists
        effect: NoSchedule
      # Mark this pod as a critical add-on; when enabled, the critical add-on
      # scheduler reserves resources for critical add-on pods so that they can
      # be rescheduled after a failure.
      # See https://kubernetes.io/docs/tasks/administer-cluster/guaranteed-scheduling-critical-addon-pods/
      priorityClassName: "system-node-critical"
      containers:
      - image: registry.cn-hangzhou.aliyuncs.com/duhao1027/k8s-device-plugin:v0.12.0
        name: nvidia-device-plugin-ctr
        env:
          - name: FAIL_ON_INIT_ERROR
            value: "false"
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop: ["ALL"]
        volumeMounts:
          - name: device-plugin
            mountPath: /var/lib/kubelet/device-plugins
      volumes:
        - name: device-plugin
          hostPath:
            path: /var/lib/kubelet/device-plugins
EOF
kubectl apply -f nvidia-device-plugin.yml

#其他节点加入k8s集群(在其他k8s集群节点执行)
kubeadm join 10.0.0.99:6443 --token abcdef.0123456789abcdef  --discovery-token-ca-cert-hash sha256:d70bea96a3ea05cb217fbb775069611c729b11f9132092744315cbf3b06ee292



##############################################################################
#查看集群节点以及节点状态是否就绪，Ready为就绪
kubectl get node
#查看每个容器运行状态(仅且显示STATUS:Running 、 READY:1/1 状态，表示容器正常运行，当所有容器正常运行时节点转为就绪状态)
kubectl get pod -n kube-system -owide
#通过如下命令定位问题(一般情况为镜像拉取失败)
kubectl describe pod 容器名 -n kube-system
kubectl describe node node1   | grep -i -n  gpu               查看k8s能不能是识别集群GPU
或
kubectl logs 容器名 -n kube-system
##################################################################################


#为gpu节点添加调度标识label,在gpu节点执行以下命令(your-gpu-node-name 替换为该节点hostname)###master执行！！！  master执行！！！master执行！！！！
#kubectl label nodes your-gpu-node-name gpu=gpu
kubectl label nodes node1 gpu=gpu

#测试集群网络（此步骤仅在master执行）
cat <<EOF > busybox_deployments.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: busybox
  labels:
    app: busybox
spec:
  replicas: 4
  selector:
    matchLabels:
      app: busybox
  template:
    metadata:
      labels:
        app: busybox
    spec:
      tolerations:
      - key: CriticalAddonsOnly
        operator: Exists
      - effect: NoSchedule
        key: node-role.kubernetes.io/master
      - effect: NoSchedule
        key: node-role.kubernetes.io/control-plane
      containers:
      - name: busybox
        image: busybox:1.28
        command:
          - sleep
          - "3600000"
EOF

kubectl apply -f busybox_deployments.yaml



#测试pod是否能解析同命名空间下域名（此步骤仅在master执行）
for i in `kubectl get pods |grep busy |awk '{print $1}'`;do kubectl exec $i -- nslookup kubernetes;done;


#测试pod是否能解析不同命名空间下域名（此步骤仅在master执行）
for i in `kubectl get pods |grep busy |awk '{print $1}'`;do echo $i;kubectl exec $i -- nslookup kube-dns.kube-system.svc.cluster.local; done;


#每个节点都必须要能访问kubernetes svc 443
telnet 172.16.0.1 443


#每个节点都必须要能访问kube-dns svc 53
sed -i '1a\nameserver 172.16.0.10' /etc/resolv.conf &&ping -c4 kube-dns.kube-system.svc.cluster.local


#节点和Pod之间要能通（此步骤仅在master执行）
for i in `kubectl get pods -owide |grep busy|awk '{print $6}'`;do ping -c4 $i;done;


#Pod和Pod之间要能通（此步骤仅在master执行）
for a in `kubectl get pods -owide |grep busy|head -1|awk '{print $1}'`;do echo $a; for i in `kubectl get pods -owide |grep busy|awk '{print $6}'`; do kubectl exec $a -- ping -c4 $i ; done; done







 
