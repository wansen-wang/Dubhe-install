部署规划
10.0.0.99 master
10.0.0.44 node1
10.0.0.74 node2
10.0.0.121 node3 
10.0.0.72 node4 #data set
10.0.0.124 node5 #NFS
10.0.0.118 node6 #front&back
#k8s集群为master+node1-3
#k8s版本为1.16.2
#docker版本为19.03.12
#calico版本为v3.9.0
#k8s pod网段为192.168.0.0/16
#k8s service网段为172.16.0.0/16

#本段操作如非特别说明，请在master节点操作
#部署数据处理算法
#安装custom-metrics-server
git clone https://github.com/stefanprodan/k8s-prom-hpa
cd k8s-prom-hpa
touch metrics-ca.key metrics-ca.crt metrics-ca-config.json
apt install -y make-guile jq unzip
make certs
sed -i 's/container_name/container/g' custom-metrics-api/custom-metrics-config-map.yaml
sed -i 's/pod_name/pod/g' custom-metrics-api/custom-metrics-config-map.yaml
kubectl apply -f custom-metrics-api/
#执行命令 出现如下结果则视为安装成功
kubectl get --raw "/apis/custom.metrics.k8s.io/v1beta1" | jq . | grep accelerator_duty_cycle

   "name": "namespaces/accelerator_duty_cycle",
   "name": "pods/accelerator_duty_cycle",




#安装算法（需要在有gpu的节点操作我选择node1）
cd /nfs    
#######这里需要上传离线包包的名称为<Dubhe-af86b91eba66b0ee4de71af3c71cc26b5e8e2d76>###############git clone  https://gitee.com/zhijiangtianshu/Dubhe-2.1.git
cd /nfs/Dubhe/dubhe_data_process
上传dubheDeployScriptfile.zip(钉钉群文件内获取)
unzip -d dubheDeployScriptfile/ dubheDeployScriptfile.zip
cd /nfs/Dubhe/dubhe_data_process/dubheDeployScriptfile/init-algorithm/

cat <<\EOF >Dockerfile
FROM nvidia/cuda:10.0-cudnn7-devel-ubuntu18.04

MAINTAINER root

RUN cp /etc/apt/sources.list /etc/apt/sources.list.bak

ADD sources.list /etc/apt/
RUN rm /etc/apt/sources.list.d/cuda.list

RUN apt-key del 7fa2af80

RUN apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/7fa2af80.pub

RUN DEBIAN_FRONTEND=noninteractive apt-get update 

RUN DEBIAN_FRONTEND=noninteractive apt-get -y install wget curl 

RUN apt-get update 

# 安装conda环境

RUN echo 'Anaconda install start'

RUN wget -P /tmp https://repo.anaconda.com/archive/Anaconda3-2020.02-Linux-x86_64.sh

RUN wget -P /tmp https://dubhe.oos-cn.ctyunapi.cn:443/oneflow.zip

RUN apt-get install -y zip

RUN unzip /tmp/oneflow.zip -d /tmp

ENV LD_LIBRARY_PATH=/tmp/darknet_dependencies/:$LD_LIBRARY_PATH

RUN sha256sum /tmp/Anaconda3-2020.02-Linux-x86_64.sh

RUN bash /tmp/Anaconda3-2020.02-Linux-x86_64.sh -b -p /usr/local/anaconda3 

ENV PATH /usr/local/anaconda3/bin:$PATH

RUN conda init bash && conda update -n base -c defaults conda

RUN /bin/bash -c "source ~/.bashrc"

RUN pip install --user -i https://mirrors.aliyun.com/pypi/simple/  scikit-image

RUN pip install --user -i https://mirrors.aliyun.com/pypi/simple/  pydicom

RUN apt-get -y install language-pack-zh-hans

RUN locale-gen en_US.UTF-8

RUN apt-get install -y libgl1-mesa-glx
RUN apt-get install -y libglib2.0-0

# 非annotation算法环境
RUN conda create -n oneflow python=3.7

RUN /usr/local/anaconda3/envs/oneflow/bin/pip install --upgrade pip

RUN /usr/local/anaconda3/envs/oneflow/bin/pip install --user -i https://mirrors.aliyun.com/pypi/simple/ /tmp/oneflow_cu102-0.3.4-cp37-cp37m-manylinux2014_x86_64.whl

RUN /usr/local/anaconda3/envs/oneflow/bin/pip install --user -i https://mirrors.aliyun.com/pypi/simple/ /tmp/oneflow_yolov3-0.0.0-py3-none-any.whl

RUN /usr/local/anaconda3/envs/oneflow/bin/pip install --user -i https://mirrors.aliyun.com/pypi/simple/ opencv-python

RUN /usr/local/anaconda3/envs/oneflow/bin/pip install --user -i https://mirrors.aliyun.com/pypi/simple/  Pillow

RUN /usr/local/anaconda3/envs/oneflow/bin/pip install --user -i https://mirrors.aliyun.com/pypi/simple/  scikit-image

RUN /usr/local/anaconda3/envs/oneflow/bin/pip install --user -i https://mirrors.aliyun.com/pypi/simple/  redis

RUN /usr/local/anaconda3/envs/oneflow/bin/pip install --user -i https://mirrors.aliyun.com/pypi/simple/  scipy

RUN /usr/local/anaconda3/envs/oneflow/bin/pip install --user -i https://mirrors.aliyun.com/pypi/simple/  nvidia-ml-py3


# annotation算法环境
RUN conda create -n oneflow-annotation python=3.5

RUN /usr/local/anaconda3/envs/oneflow-annotation/bin/pip install --upgrade pip

RUN /usr/local/anaconda3/envs/oneflow-annotation/bin/pip install --user -i https://mirrors.aliyun.com/pypi/simple/ /tmp/oneflow-0.0.1-cp35-cp35m-linux_x86_64.whl

RUN /usr/local/anaconda3/envs/oneflow-annotation/bin/pip install --user -i https://mirrors.aliyun.com/pypi/simple/ /tmp/oneflow_yolov3-0.0.0-py3-none-any.whl

RUN /usr/local/anaconda3/envs/oneflow-annotation/bin/pip install --user -i https://mirrors.aliyun.com/pypi/simple/ opencv-python

RUN /usr/local/anaconda3/envs/oneflow-annotation/bin/pip install --user -i https://mirrors.aliyun.com/pypi/simple/  web.py

RUN /usr/local/anaconda3/envs/oneflow-annotation/bin/pip install --user -i https://mirrors.aliyun.com/pypi/simple/  scikit-image

RUN /usr/local/anaconda3/envs/oneflow-annotation/bin/pip install --user -i https://mirrors.aliyun.com/pypi/simple/  Pillow

RUN /usr/local/anaconda3/envs/oneflow-annotation/bin/pip install --user -i https://mirrors.aliyun.com/pypi/simple/  redis

RUN /usr/local/anaconda3/envs/oneflow-annotation/bin/pip install --user -i https://mirrors.aliyun.com/pypi/simple/  scipy

RUN /usr/local/anaconda3/envs/oneflow-annotation/bin/pip install --user -i https://mirrors.aliyun.com/pypi/simple/  nvidia-ml-py3

RUN echo 'success!!!'
EOF
docker build -t harbor.wsco.com/algorithm/algorithm:v1 .
docker login harbor.wsco.com
输入用户名和密码
登录https://www.harbor.wsco.com
创建新项目名字为： algorithm
docker push harbor.wsco.com/algorithm/algorithm:v1






#部署算法deployment（在master节点执行）
cd /nfs/Dubhe/dubhe_data_process/dubheDeployScriptfile/init-algorithm
cat <<\EOF >algorithm-annotation.yaml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: algorithm-annotation
spec:
  selector:
    matchLabels:
      app: algorithm-annotation
  replicas: 2
  template:
    metadata:
      labels:
        app: algorithm-annotation
      annotations:
        prometheus.io/scrape: "true"
    spec:
      terminationGracePeriodSeconds: 60
      containers:
      - name: algorithm-annotation
        image: harbor.wsco.com/algorithm/algorithm:v1
        imagePullPolicy: IfNotPresent
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh","-c","cd /root/algorithm; chmod a+x stop.sh; bash stop.sh; sleep 60"]
        command: ["/bin/bash","-c","cd /root; rm -rf algorithm; wget https://dubhe.oos-cn.ctyunapi.cn:443/algorithm.zip -O algorithm.zip; apt install unzip; unzip algorithm.zip; cd /root/algorithm; chmod a+x init.sh; bash init.sh annotation /nfs/Dubhe/dubhe_data_process 10.0.0.124 '' 0 6379"]
        volumeMounts:
        - name: algorithm-annotation-nfs
          mountPath: /nfs
        ports:
        - containerPort: 9898
          protocol: TCP
        resources:
          requests:
            cpu: "1000m"
            memory: "2Gi"
            nvidia.com/gpu: "0"
          limits:
            cpu: "2000m"
            memory: "4Gi"
            nvidia.com/gpu: "0"
      volumes:
      - name: algorithm-annotation-nfs
        nfs:
          server: 10.0.0.124
          path: /nfs
EOF

cat <<\EOF >algorithm-ofrecord.yaml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: algorithm-ofrecord
spec:
  selector:
    matchLabels:
      app: algorithm-ofrecord
  replicas: 2
  template:
    metadata:
      labels:
        app: algorithm-ofrecord
      annotations:
        prometheus.io/scrape: "true"
    spec:
      terminationGracePeriodSeconds: 1200
      containers:
      - name: algorithm-ofrecord
        image: harbor.wsco.com/algorithm/algorithm:v1
        imagePullPolicy: IfNotPresent
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh","-c","cd /root/algorithm; chmod a+x stop.sh; bash stop.sh; sleep 1200"]
        command: ["/bin/bash","-c","cd /root; rm -rf algorithm; wget https://dubhe.oos-cn.ctyunapi.cn:443/algorithm.zip -O algorithm.zip; apt ins
tall unzip; unzip algorithm.zip; cd /root/algorithm; chmod a+x init.sh; bash init.sh ofrecord /nfs/Dubhe/dubhe_data_process 10.0.0.124 '' 0 6379"]
        volumeMounts:
        - name: algorithm-ofrecord-fs
          mountPath: /nfs
        ports:
        - containerPort: 9898
          protocol: TCP
        resources:
          requests:
            cpu: "1000m"
            memory: "2Gi"
          limits:
            cpu: "2000m"
            memory: "4Gi"
      volumes:
      - name: algorithm-ofrecord-fs
        nfs:
          server: 10.0.0.124
          path: /nfs
EOF

cat <<\EOF >algorithm-imagenet.yaml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: algorithm-imagenet
spec:
  selector:
    matchLabels:
      app: algorithm-imagenet
  replicas: 2
  template:
    metadata:
      labels:
        app: algorithm-imagenet
      annotations:
        prometheus.io/scrape: "true"
    spec:
      terminationGracePeriodSeconds: 60
      containers:
      - name: algorithm-imagenet
        image: harbor.wsco.com/algorithm/algorithm:v1
        imagePullPolicy: IfNotPresent
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh","-c","cd /root/algorithm; chmod a+x stop.sh; bash stop.sh; sleep 60"]
        command: ["/bin/bash","-c","cd /root; rm -rf algorithm; wget https://dubhe.oos-cn.ctyunapi.cn:443/algorithm.zip -O algorithm.zip; apt ins
tall unzip; unzip algorithm.zip; cd /root/algorithm; chmod a+x init.sh; bash init.sh imagenet /nfs/Dubhe/dubhe_data_process 10.0.0.124 '' 0 6379"]
        volumeMounts:
        - name: algorithm-imagenet-fs
          mountPath: /nfs
        ports:
        - containerPort: 9898
          protocol: TCP
        resources:
          requests:
            cpu: "1000m"
            memory: "2Gi"
            nvidia.com/gpu: "0"
          limits:
            cpu: "2000m"
            memory: "4Gi"
            nvidia.com/gpu: "0"
      volumes:
      - name: algorithm-imagenet-fs
        nfs:
          server: 10.0.0.124
          path: /nfs
EOF

cat <<\EOF >algorithm-imgprocess.yaml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: algorithm-imgprocess
spec:
  selector:
    matchLabels:
      app: algorithm-imgprocess
  replicas: 2
  template:
    metadata:
      labels:
        app: algorithm-imgprocess
      annotations:
        prometheus.io/scrape: "true"
    spec:
      terminationGracePeriodSeconds: 60
      containers:
      - name: algorithm-imgprocess
        image: harbor.wsco.com/algorithm/algorithm:v1
        imagePullPolicy: IfNotPresent
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh","-c","cd /root/algorithm; chmod a+x stop.sh; bash stop.sh; sleep 60"]
        command: ["/bin/bash","-c","cd /root; rm -rf algorithm; wget https://dubhe.oos-cn.ctyunapi.cn:443/algorithm.zip -O algorithm.zip; apt ins
tall unzip; unzip algorithm.zip; cd /root/algorithm; chmod a+x init.sh; bash init.sh imgprocess /nfs/Dubhe/dubhe_data_process 10.0.0.124 '' 0 6379"]
        volumeMounts:
        - name: algorithm-imgprocess-fs
          mountPath: /nfs
        ports:
        - containerPort: 9898
          protocol: TCP
        resources:
          requests:
            cpu: "1000m"
            memory: "2Gi"
          limits:
            cpu: "2000m"
            memory: "4Gi"
      volumes:
      - name: algorithm-imgprocess-fs
        nfs:
          server: 10.0.0.124
          path: /nfs
EOF

cat <<\EOF > algorithm-track.yaml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: algorithm-track
spec:
  selector:
    matchLabels:
      app: algorithm-track
  replicas: 2
  template:
    metadata:
      labels:
        app: algorithm-track
      annotations:
        prometheus.io/scrape: "true"
    spec:
      terminationGracePeriodSeconds: 60
      containers:
      - name: algorithm-track
        image: harbor.wsco.com/algorithm/algorithm:v1
        imagePullPolicy: IfNotPresent
        command: ["/bin/bash","-c","cd /root; rm -rf algorithm; wget https://dubhe.oos-cn.ctyunapi.cn:443/algorithm.zip -O algorithm.zip; apt ins
tall unzip; unzip algorithm.zip; cd /root/algorithm; chmod a+x init.sh; bash init.sh track /nfs/Dubhe/dubhe_data_process 10.0.0.124 '' 0 6379"]
        volumeMounts:
        - name: algorithm-track-fs
          mountPath: /nfs
        ports:
        - containerPort: 9898
          protocol: TCP
        resources:
          requests:
            cpu: "1000m"
            memory: "2Gi"
          limits:
            cpu: "2000m"
            memory: "4Gi"
      volumes:
      - name: algorithm-track-fs
        nfs:
          server: 10.0.0.124
          path: /nfs
EOF

cat <<\EOF >algorithm-videosample.yaml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: algorithm-videosample
spec:
  selector:
    matchLabels:
      app: algorithm-videosample
  replicas: 2
  template:
    metadata:
      labels:
        app: algorithm-videosample
      annotations:
        prometheus.io/scrape: "true"
    spec:
      terminationGracePeriodSeconds: 1200
      containers:
      - name: algorithm-videosample
        image: harbor.wsco.com/algorithm/algorithm:v1
        imagePullPolicy: IfNotPresent
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh","-c","cd /root/algorithm; chmod a+x stop.sh; bash stop.sh; sleep 1200"]
        command: ["/bin/bash","-c","cd /root; rm -rf algorithm; wget https://dubhe.oos-cn.ctyunapi.cn:443/algorithm.zip -O algorithm.zip; apt install unzip; unzip algorithm.zip; cd /root/algorithm; chmod a+x init.sh; bash init.sh videosample /nfs/Dubhe/dubhe_data_process 10.0.0.124 '' 0 6379"]
        volumeMounts:
        - name: algorithm-videosample-fs
          mountPath: /nfs
        ports:
        - containerPort: 9898
          protocol: TCP
        resources:
          requests:
            cpu: "1000m"
            memory: "2Gi"
          limits:
            cpu: "2000m"
            memory: "4Gi"
      volumes:
      - name: algorithm-videosample-fs
        nfs:
          server: 10.0.0.124
          path: /nfs
EOF

cat <<\EOF > algorithm-lungsegmentation.yaml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: algorithm-lungsegmenatation
spec:
  selector:
    matchLabels:
      app: algorithm-lungsegmenatation
  replicas: 2
  template:
    metadata:
      labels:
        app: algorithm-lungsegmenatation
      annotations:
        prometheus.io/scrape: "true"
    spec:
      terminationGracePeriodSeconds: 60
      containers:
      - name: algorithm-lungsegmenatation
        image: harbor.wsco.com/algorithm/algorithm:v1
        imagePullPolicy: IfNotPresent
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh","-c","cd /root/algorithm; chmod a+x stop.sh; bash stop.sh; sleep 60"]
        command: ["/bin/bash","-c","cd /root; rm -rf algorithm; wget https://dubhe.oos-cn.ctyunapi.cn:443/algorithm.zip -O algorithm.zip; apt ins
tall unzip; unzip algorithm.zip; cd /root/algorithm; chmod a+x init.sh; bash init.sh lung_segmentation /nfs/Dubhe/dubhe_data_process 10.0.0.124 '' 0 6379"]
        volumeMounts:
        - name: algorithm-lungsegmenatation-fs
          mountPath: /nfs
        ports:
        - containerPort: 9898
          protocol: TCP
        resources:
          requests:
            cpu: "1000m"
            memory: "2Gi"
          limits:
            cpu: "2000m"
            memory: "4Gi"
      volumes:
      - name: algorithm-lungsegmenatation-fs
        nfs:
          server: 10.0.0.124
          path: /nfs
EOF

cat <<\EOF > algorithm-text-classification.yaml
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: algorithm-text-classification
spec:
  selector:
    matchLabels:
      app: algorithm-text-classification
  replicas: 2
  template:
    metadata:
      labels:
        app: algorithm-text-classification
      annotations:
        prometheus.io/scrape: "true"
    spec:
      terminationGracePeriodSeconds: 60
      containers:
      - name: algorithm-text-classification
        image: harbor.wsco.com/algorithm/algorithm:v1
        imagePullPolicy: IfNotPresent
        lifecycle:
          preStop:
            exec:
              command: ["/bin/sh","-c","cd /root/algorithm; chmod a+x stop.sh; bash stop.sh; sleep 60"]
        command: ["/bin/bash","-c","cd /root; rm -rf algorithm; wget https://dubhe.oos-cn.ctyunapi.cn:443/algorithm.zip -O algorithm.zip; apt ins
tall unzip; unzip algorithm.zip; cd /root/algorithm; chmod a+x init.sh; bash init.sh text_classification /nfs/Dubhe/dubhe_data_process 10.0.0.124 '' 0 6379"]
        volumeMounts:
        - name: algorithm-text-classification-fs
          mountPath: /nfs
        ports:
        - containerPort: 9898
          protocol: TCP
        resources:
          requests:
            cpu: "1000m"
            memory: "2Gi"
          limits:
            cpu: "2000m"
            memory: "4Gi"
      volumes:
      - name: algorithm-text-classification-fs
        nfs:
          server: 10.0.0.124
          path: /nfs
EOF
# 标注算法(部署有问题，pod起不来，初步怀疑代码有问题)
kubectl apply -f algorithm-annotation.yaml
kubectl apply -f algorithm-annotation-hpa.yaml
# ofrecord 数据转换算法
kubectl apply -f algorithm-ofrecord.yaml
kubectl apply -f algorithm-ofrecord-hpa.yaml
# imagenet 算法(部署有问题，pod起不来，初步怀疑代码有问题)
kubectl apply -f algorithm-imagenet.yaml
kubectl apply -f algorithm-imagenet-hpa.yaml
# 增强算法
kubectl apply -f algorithm-imgprocess.yaml
kubectl apply -f algorithm-imgprocess-hpa.yaml
# 目标跟踪算法
kubectl apply -f algorithm-track.yaml
# videosample 算法
kubectl apply -f algorithm-videosample.yaml
kubectl apply -f algorithm-videosample-hpa.yaml
# 医学标注算法算法
kubectl apply -f algorithm-lungsegmentation.yaml
kubectl apply -f algorithm-lungsegmentation-hpa.yaml
# nlp文本标注算法(部署有问题，pod起不来，初步怀疑代码有问题)
kubectl apply -f algorithm-text-classification.yaml
kubectl apply -f algorithm-text-classification-hpa.yaml
#等待 pod 全部变为 running 状态。




#部署云端服务
cd /nfs/Dubhe/dubhe_data_process/dubheDeployScriptfile/init-algorithm/
#写入Dockerfile（需要在有gpu的节点操作我选择node1）                 #######部署时下载超时多试几次就行#########################################
cat <<\EOF > Dockerfile
# 根据宿主机的cuda版本拉取对应的cuda镜像
FROM nvidia/cuda:10.0-cudnn7-devel-ubuntu18.04
# 删除nvidia更新源以避免apt update失败，安装python3-pip会同时安装python3
RUN rm -rf /etc/apt/sources.list.d && apt update && apt install -y python3-pip
# 建立python软连接到python3，以兼容使用python运行命令的情况
RUN ln -s /usr/bin/python3 /usr/bin/python
# 升级pip3以支持manylinux的方式安装wheel包
RUN pip3 install --upgrade pip && \
    #安装深度框架
    pip install tensorflow-gpu==2.1.0 -i https://pypi.douban.com/simple/ && \
    python3 -m pip install --find-links https://oneflow-static.oss-cn-beijing.aliyuncs.com/staging/dev_serving/pip.index.html oneflow_cu102 && \
    pip install torch==1.6.0 torchvision==0.7.0 && \
    #安装serving需要的python第三方库
    pip install fastapi && \
    pip install python-multipart && \
    pip install uvicorn && \
    pip install numpy
EOF
docker build -t harbor.wsco.com/serving/serving-gpu:base .
推送之前在harbor仓库创建新项目名称为serving
docker push harbor.wsco.com/serving/serving-gpu:base

把镜像地址及 serving 代码路径配置到天枢后台代码的配置文件中，后续将由天枢后端服务调用 k8s 启动该服务
serving:
  gpu-image: harbor.wsco.com/serving/serving-gpu:base
  sourcePath: "/nfs/Dubhe/tianshu_serving"              ######不用改，不用改，不用改！！！！
启动服务
在天枢平台云端部署 模块中进行在线服务和批量服务创建即可。







#部署模型优化服务
cd /nfs/Dubhe/dubhe_data_process/dubheDeployScriptfile/init-algorithm/
#写入Dockerfile（需要在有gpu的节点操作我选择node1）
cat <<\EOF > Dockerfile
FROM nvidia/cuda:10.2-cudnn7-devel-ubuntu18.04
RUN rm -rf /etc/apt/sources.list.d && apt update && apt install -y build-essential zlib1g-dev libncurses5-dev libgdbm-dev libnss3-dev libssl-dev libreadline-dev libffi-dev wget
RUN wget https://www.python.org/ftp/python/3.6.11/Python-3.6.11.tgz && \
    tar -zxvf Python-3.6.11.tgz && \
    rm -rf Python-3.6.11.tgz && \
    cd Python-3.6.11 && ./configure prefix=/usr/local/python3 && \
    make && make install && \
    rm -rf /usr/local/Python-3.6.11 && \
    rm -rf /usr/bin/python && \
    rm -rf /usr/bin/python3 && \
    rm -rf /usr/bin/python3.6 && \
    rm -rf /usr/bin/pip && \
    rm -rf /usr/bin/pip3 && \
    ln -s /usr/local/python3/bin/python3.6 /usr/bin/python && \
    ln -s /usr/local/python3/bin/python3.6 /usr/bin/python3 && \
    ln -s /usr/local/python3/bin/python3.6 /usr/bin/python3.6 && \
    ln -s /usr/local/python3/bin/pip3 /usr/bin/pip && \
    ln -s /usr/local/python3/bin/pip3 /usr/bin/pip3 && \
    pip install --upgrade pip && \
    pip install https://oneflow-static.oss-cn-beijing.aliyuncs.com/pip/oneflow-0.3b3-cp36-cp36m-linux_x86_64.whl && \
    pip install numpy==1.19.5 && \
    pip install pandas==1.1.5 && \
    pip install image==1.5.33 && \
    pip install Pillow==8.1.0 && \
    pip install tqdm==4.55.1 
EOF
docker build -t harbor.wsco.com/optimize/oneflow-gpu:base .
docker push harbor.wsco.com/optimize/oneflow-gpu:base              ##############################################未上传

并将镜像地址配置到天枢平台后端代码的配置文件中，如：
Copy
optimize:
    image: harbor.wsco.com/optimize/oneflow-gpu:base
	



#部署自动机器学习服务(master 节点无法部署可能是没有GPU的原因)
cd /nfs/Dubhe/dubhe_data_process/dubheDeployScriptfile/init-algorithm/
cat <<\EOF > Dockerfile
FROM nvidia/cuda:11.2.2-cudnn8-devel-centos7
  
# 删除nvidia更新源以避免apt update失败，安装python3-pip会同时安装python3
RUN rm -rf /etc/yum.repos.d/*.repo
RUN curl http://mirrors.aliyun.com/repo/Centos-7.repo?spm=a2c6h.25603864.0.0.3d975969fPiKGq >> /etc/yum.repos.d/Centos-7.repo
RUN yum update -y
RUN yum install -y python3-devel xz-devel
#删除python软连接，防止有其他版本
RUN rm -rf /usr/bin/python

# 建立python软连接到python3，以兼容使用python运行命令的情况
RUN ln -s /usr/bin/python3 /usr/bin/python
# 升级pip3以支持manylinux的方式安装wheel包
RUN pip3 install --upgrade pip
#RUN pip3 install -U --force-reinstall pip

ENV TZ=Asia/Shanghai
RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime && echo $TZ > /etc/timezone

    #安装深度框架
RUN pip install torch==1.7.1 torchvision==0.8.2 -i https://pypi.mirrors.ustc.edu.cn/simple
    #安装python依赖包
RUN pip3 install backports.lzma==0.0.14 && \
    pip3 install dataclasses==0.8 && \
    pip3 install joblib==1.0.1 && \
    pip3 --default-timeout=1000 install numpy==1.19.4 -i https://pypi.douban.com/simple/ --trusted-host pypi.douban.com && \
    pip3 install Pillow==8.0.1 && \
    pip3 install ptflops==0.6.4 && \
    pip3 install PyYAML==5.4.1 && \
        pip3 --default-timeout=1000 install scikit-learn==0.24.2 -i http://pypi.douban.com/simple/ --trusted-host pypi.douban.com && \
    pip3 install scipy==1.5.4 && \
    pip3 install sklearn==0.0 && \
    pip3 install thop==0.0.31.post2005241907 && \
    pip3 install threadpoolctl==2.2.0 && \
    pip3 install timm==0.3.4 && \
    pip3 install typing-extensions==3.7.4.3 && \
    pip3 install yacs==0.1.8 -i https://pypi.mirrors.ustc.edu.cn/simple
EOF
docker build -t harbor.wsco.com/automl/nas-pytorch17  .
docker push harbor.wsco.com/automl/nas-pytorch17




#部署模型转换算法（必须master节点部署）
mkdir /nfs/dubhe-prod/model/
cd /nfs/Dubhe/dubhe_data_process/dubheDeployScriptfile/model_converter
chmod a+x deploy_converter.sh
bash deploy_converter.sh
期间需要输入
harbor私有仓库地址：harbor.wsco.com
用户名：admin
用户秘密：Harbor12345
#项目名称：dubhe-prod
#部署完成后，执行以下命令，查看算法是否部署成功：
#查看 Pod model-converter-prod-0 是否为 Running 状态                #单机部署是状态位pending
#查看 Service model-converter-prod 是否存在                          # 状态为none
kubectl get pod,svc -n kube-system |grep model




#部署模型度量算法（需要在有gpu的节点操作我选择node1）
mkdir /root/.kube/ && scp master:/root/.kube/config /root/.kube/config 
mkdir /nfs/dubhe-prod/dataset
mkdir /nfs/dubhe-prod/exported-metrics/
cd /nfs/Dubhe/dubhe_data_process/dubheDeployScriptfile/model_measuring/
chmod a+x deploy_measuring.sh
bash deploy_measuring.sh
期间需要输入harbor服务器地址，用户名，密码。和项目名称这个项目名称就是，需要提前创建好项目
如果pod没有起来需要用一下命令查看pod具体运行状态，然后可能是要创建两个文件夹
kubectl describe pods -n kube-system <pod_name>



